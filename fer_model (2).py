# -*- coding: utf-8 -*-
"""FER_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c6Ogn6HtlAu4hXC1jXJedsNZPEMQfxD0

Upload zipped dataset and unzip
"""

from google.colab import files
uploaded = files.upload()  # Upload your 'archive.zip'

import zipfile
import os

# Unzip archive.zip
with zipfile.ZipFile('data.zip', 'r') as zip_ref:
    zip_ref.extractall('fer2013_data')

# Confirm folder structure
os.listdir('fer2013_data')

"""Import required libraries"""

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import os

"""Load the dataset"""

data_path = 'fer2013_data/data'

# Augment training images
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=15,
    zoom_range=0.1,
    horizontal_flip=True
)

# Only rescale for val/test
val_test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    os.path.join(data_path,'train'),
    target_size=(48, 48),
    color_mode='grayscale',
    class_mode='categorical',
    batch_size=64
)

val_generator = val_test_datagen.flow_from_directory(
    os.path.join(data_path, 'val'),
    target_size=(48, 48),
    color_mode='grayscale',
    class_mode='categorical',
    batch_size=64
)

test_generator = val_test_datagen.flow_from_directory(
    os.path.join(data_path, 'test'),
    target_size=(48, 48),
    color_mode='grayscale',
    class_mode='categorical',
    batch_size=64,
    shuffle=False
)

"""Build and Compile CNN Model"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense

model = Sequential([
    Conv2D(64, (3, 3), activation='relu', input_shape=(48, 48, 1)),
    MaxPooling2D(pool_size=(2, 2)),
    Dropout(0.25),

    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Dropout(0.25),

    Flatten(),
    Dense(256, activation='relu'),
    Dropout(0.5),
    Dense(7, activation='softmax')  # Assuming 7 emotion classes
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

"""Train the Model"""

history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=25
)

"""Visualize Accuracy and Loss"""

plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.legend()
plt.title("Accuracy over Epochs")
plt.show()

"""Confusion Matrix & Classification Report"""

from sklearn.metrics import confusion_matrix, classification_report

# Predict
y_pred = model.predict(test_generator)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = test_generator.classes

# Class labels
labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']

# Classification Report
print(classification_report(y_true, y_pred_classes, target_names=labels))

# Confusion Matrix
cm = confusion_matrix(y_true, y_pred_classes)
sns.heatmap(cm, annot=True, xticklabels=labels, yticklabels=labels, fmt='d', cmap='Blues')
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

"""Save model

"""

model.save("fer13_imagefolder_model.h5")
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
import cv2
import tensorflow as tf
from tensorflow.keras.layers import Dense, Dropout, Flatten, Convolution2D, MaxPooling2D
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array
from sklearn.metrics import classification_report

# Model definition
model = Sequential()
model.add(Convolution2D(64, (5, 5), input_shape=(48, 48, 1), activation='relu'))
model.add(Convolution2D(64, (5, 5), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.4))
model.add(Convolution2D(128, (3, 3), activation='relu'))
model.add(Convolution2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.4))
model.add(Flatten())
model.add(Dense(units=128, activation='relu'))
model.add(Dense(units=7, activation='softmax'))
model.summary()

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=30, shear_range=0.3, zoom_range=0.3, horizontal_flip=False)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory('/content/Training', target_size=(48, 48), batch_size=512, color_mode='grayscale', class_mode='categorical')
validation_generator = test_datagen.flow_from_directory('/content/Testing', target_size=(48, 48), batch_size=512, color_mode='grayscale', class_mode='categorical')

filepath = os.path.join("./emotion_detector/models/model_v{epoch}.hdf5")
checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')
callbacks = [checkpoint]

nb_train_samples = 28709
nb_validation_samples = 717
batch_size = 512

history = model.fit(train_generator, steps_per_epoch=nb_train_samples // batch_size, epochs=50,
                    validation_data=validation_generator, callbacks=callbacks,
                    validation_steps=nb_validation_samples // batch_size)

fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(20, 6))
ax1.plot(history.history['accuracy'], label='train_accuracy')
ax1.plot(history.history['val_accuracy'], label='test_accuracy')
ax1.legend()
ax2.plot(history.history['loss'], label='train_loss')
ax2.plot(history.history['val_loss'], label='test_loss')
ax2.legend()
plt.show()

# Real-time detection part
face_classifier = cv2.CascadeClassifier('./Harcascade/haarcascade_frontalface_default.xml')
classifier = load_model('./Models/model_v47.hdf5')
class_labels = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Neutral', 5: 'Sad', 6: 'Surprise'}

cap = cv2.VideoCapture(0)

while True:
    ret, img = cap.read()
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    faces = face_classifier.detectMultiScale(gray, 1.3, 5)
    all_faces = []
    rects = []

    for (x, y, w, h) in faces:
        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)
        roi_gray = gray[y:y+h, x:x+w]
        roi_gray = cv2.resize(roi_gray, (48, 48), interpolation=cv2.INTER_AREA)
        all_faces.append(roi_gray)
        rects.append((x, w, y, h))

    i = 0
    for face in all_faces:
        roi = face.astype("float") / 255.0
        roi = img_to_array(roi)
        roi = np.expand_dims(roi, axis=0)
        preds = classifier.predict(roi)[0]
        label = class_labels[preds.argmax()]
        label_position = (rects[i][0] + int((rects[i][1]) / 2), abs(rects[i][2] - 10))
        cv2.putText(img, label, label_position, cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        i += 1

    cv2.imshow("MENTAL HEALTH IDENTIFICATION", img)
    if cv2.waitKey(1) == 13:  # Enter key
        break

cap.release()
cv2.destroyAllWindows()
